# Day 1 - Running Local LLM with Ollama

## Goal
Run a local Large Language Model (LLM) on my machine as the first step into LLMOps.

## What I Did
- Installed Ollama
- Ran `phi3` model locally
- Interacted with the model via terminal
- Tested basic DevOps-related prompts

## Tools Used
- Ollama
- phi3

## Sample Prompt
"You are my DevOps assistant. Explain what a Linux service is?"

## Learning Outcome
I learned how to run an open-source LLM locally and interact with it without any cloud dependency.
This is the foundation for building autonomous AI agents.
